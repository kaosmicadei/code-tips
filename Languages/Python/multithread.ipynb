{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Parallelising tasks\n",
    "\n",
    "When working with large simulation it's common to have tasks that take long to run but that are not dependent on each other. Such tasks could be easily split into partial tasks (chunks), run in different processes, and finally glued in a summarise process.\n",
    "\n",
    "Take for example the over used case of counting words in a text."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text extracted from https://en.wikipedia.org/wiki/MapReduce\n",
    "\n",
    "text = \"mapreduce is a programming model and an associated implementation for processing and generating bigdata sets with a parallel distributed algorithm on a cluster a mapreduce program is composed of a map procedure which performs filtering and sorting such as sorting students by first name into queues one queue for each name and a reduce method which performs a summary operation such as counting the number of students in each queue yielding name frequencies the mapreduce system also called infrastructure or framework orchestrates the processing by marshalling the distributed servers running the various tasks in parallel managing all communications and data transfers between the various parts of the system and providing for redundancy and fault tolerance the model is a specialization of the splitapplycombine strategy for data analysis it is inspired by the map and reduce functions commonly used in functional programming although their purpose in the mapreduce framework is not the same as in their original forms the key contributions of the mapreduce framework are not the actual map and reduce functions which for example resemble the message passing interface standard reduce and scatter operations but the scalability and faulttolerance achieved for a variety of applications by optimizing the execution engine as such a singlethreaded implementation of mapreduce is usually not faster than a traditional nonmapreduce implementation any gains are usually only seen with multithreaded implementations on multiprocessor hardware the use of this model is beneficial only when the optimized distributed shuffle operation which reduces network communication cost and fault tolerance features of the mapreduce framework come into play optimizing the communication cost is essential to a good mapreduce algorithm mapreduce libraries have been written in many programming languages with different levels of optimization a popular opensource implementation that has support for distributed shuffles is part of apache hadoop the name mapreduce originally referred to the proprietary google technology but has since been genericized by google was no longer using mapreduce as their primary bigdata processing model and development on apache mahout had moved on to more capable and less diskoriented mechanisms that incorporated full map and reduce capabilities\""
   ]
  },
  {
   "source": [
    "The idea here is use every word as a key in a hastable (dictionary) and store the counting as the respective value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'mapreduce': 11, 'is': 9, 'a': 13, 'programming': 3, 'model': 4, 'and': 15, 'an': 1, 'associated': 1, 'implementation': 4, 'for': 7, 'processing': 3, 'generating': 1, 'bigdata': 2, 'sets': 1, 'with': 3, 'parallel': 2, 'distributed': 4, 'algorithm': 2, 'on': 4, 'cluster': 1, 'program': 1, 'composed': 1, 'of': 11, 'map': 4, 'procedure': 1, 'which': 4, 'performs': 2, 'filtering': 1, 'sorting': 2, 'such': 3, 'as': 5, 'students': 2, 'by': 5, 'first': 1, 'name': 4, 'into': 2, 'queues': 1, 'one': 1, 'queue': 2, 'each': 2, 'reduce': 5, 'method': 1, 'summary': 1, 'operation': 2, 'counting': 1, 'the': 24, 'number': 1, 'in': 6, 'yielding': 1, 'frequencies': 1, 'system': 2, 'also': 1, 'called': 1, 'infrastructure': 1, 'or': 1, 'framework': 4, 'orchestrates': 1, 'marshalling': 1, 'servers': 1, 'running': 1, 'various': 2, 'tasks': 1, 'managing': 1, 'all': 1, 'communications': 1, 'data': 2, 'transfers': 1, 'between': 1, 'parts': 1, 'providing': 1, 'redundancy': 1, 'fault': 2, 'tolerance': 2, 'specialization': 1, 'splitapplycombine': 1, 'strategy': 1, 'analysis': 1, 'it': 1, 'inspired': 1, 'functions': 2, 'commonly': 1, 'used': 1, 'functional': 1, 'although': 1, 'their': 3, 'purpose': 1, 'not': 3, 'same': 1, 'original': 1, 'forms': 1, 'key': 1, 'contributions': 1, 'are': 2, 'actual': 1, 'example': 1, 'resemble': 1, 'message': 1, 'passing': 1, 'interface': 1, 'standard': 1, 'scatter': 1, 'operations': 1, 'but': 2, 'scalability': 1, 'faulttolerance': 1, 'achieved': 1, 'variety': 1, 'applications': 1, 'optimizing': 2, 'execution': 1, 'engine': 1, 'singlethreaded': 1, 'usually': 2, 'faster': 1, 'than': 1, 'traditional': 1, 'nonmapreduce': 1, 'any': 1, 'gains': 1, 'only': 2, 'seen': 1, 'multithreaded': 1, 'implementations': 1, 'multiprocessor': 1, 'hardware': 1, 'use': 1, 'this': 1, 'beneficial': 1, 'when': 1, 'optimized': 1, 'shuffle': 1, 'reduces': 1, 'network': 1, 'communication': 2, 'cost': 2, 'features': 1, 'come': 1, 'play': 1, 'essential': 1, 'to': 3, 'good': 1, 'libraries': 1, 'have': 1, 'been': 2, 'written': 1, 'many': 1, 'languages': 1, 'different': 1, 'levels': 1, 'optimization': 1, 'popular': 1, 'opensource': 1, 'that': 2, 'has': 2, 'support': 1, 'shuffles': 1, 'part': 1, 'apache': 2, 'hadoop': 1, 'originally': 1, 'referred': 1, 'proprietary': 1, 'google': 2, 'technology': 1, 'since': 1, 'genericized': 1, 'was': 1, 'no': 1, 'longer': 1, 'using': 1, 'primary': 1, 'development': 1, 'mahout': 1, 'had': 1, 'moved': 1, 'more': 1, 'capable': 1, 'less': 1, 'diskoriented': 1, 'mechanisms': 1, 'incorporated': 1, 'full': 1, 'capabilities': 1}\n"
     ]
    }
   ],
   "source": [
    "def count_words(words):\n",
    "    bucket = {}\n",
    "    for word in words:\n",
    "        bucket[word] = bucket.get(word, 0) + 1\n",
    "    return bucket\n",
    "\n",
    "print(count_words(text.split()))"
   ]
  },
  {
   "source": [
    "Works pretty well. However, if the task was really time consuming we would have to wait the whole process finish before continue.\n",
    "\n",
    "But if we split the problem into small groups and run each group in a isolated thread, then we could have the same job done in a short time. To do so first we need to chunk the data (the text in this case)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'mapreduce': 2, 'is': 2, 'a': 5, 'programming': 1, 'model': 1, 'and': 3, 'an': 1, 'associated': 1, 'implementation': 1, 'for': 2, 'processing': 1, 'generating': 1, 'bigdata': 1, 'sets': 1, 'with': 1, 'parallel': 1, 'distributed': 1, 'algorithm': 1, 'on': 1, 'cluster': 1, 'program': 1, 'composed': 1, 'of': 1, 'map': 1, 'procedure': 1, 'which': 1, 'performs': 1, 'filtering': 1, 'sorting': 2, 'such': 1, 'as': 1, 'students': 1, 'by': 1, 'first': 1, 'name': 1, 'into': 1, 'queues': 1, 'one': 1, 'queue': 1, 'each': 1}\n\n{'name': 2, 'and': 2, 'a': 2, 'reduce': 1, 'method': 1, 'which': 1, 'performs': 1, 'summary': 1, 'operation': 1, 'such': 1, 'as': 1, 'counting': 1, 'the': 5, 'number': 1, 'of': 1, 'students': 1, 'in': 2, 'each': 1, 'queue': 1, 'yielding': 1, 'frequencies': 1, 'mapreduce': 1, 'system': 1, 'also': 1, 'called': 1, 'infrastructure': 1, 'or': 1, 'framework': 1, 'orchestrates': 1, 'processing': 1, 'by': 1, 'marshalling': 1, 'distributed': 1, 'servers': 1, 'running': 1, 'various': 1, 'tasks': 1, 'parallel': 1, 'managing': 1, 'all': 1, 'communications': 1, 'data': 1}\n\n{'transfers': 1, 'between': 1, 'the': 6, 'various': 1, 'parts': 1, 'of': 2, 'system': 1, 'and': 3, 'providing': 1, 'for': 2, 'redundancy': 1, 'fault': 1, 'tolerance': 1, 'model': 1, 'is': 3, 'a': 1, 'specialization': 1, 'splitapplycombine': 1, 'strategy': 1, 'data': 1, 'analysis': 1, 'it': 1, 'inspired': 1, 'by': 1, 'map': 1, 'reduce': 1, 'functions': 1, 'commonly': 1, 'used': 1, 'in': 2, 'functional': 1, 'programming': 1, 'although': 1, 'their': 1, 'purpose': 1, 'mapreduce': 1, 'framework': 1, 'not': 1}\n\n{'the': 7, 'same': 1, 'as': 1, 'in': 1, 'their': 1, 'original': 1, 'forms': 1, 'key': 1, 'contributions': 1, 'of': 2, 'mapreduce': 1, 'framework': 1, 'are': 1, 'not': 1, 'actual': 1, 'map': 1, 'and': 3, 'reduce': 2, 'functions': 1, 'which': 1, 'for': 2, 'example': 1, 'resemble': 1, 'message': 1, 'passing': 1, 'interface': 1, 'standard': 1, 'scatter': 1, 'operations': 1, 'but': 1, 'scalability': 1, 'faulttolerance': 1, 'achieved': 1, 'a': 1, 'variety': 1, 'applications': 1, 'by': 1, 'optimizing': 1, 'execution': 1}\n\n{'engine': 1, 'as': 1, 'such': 1, 'a': 2, 'singlethreaded': 1, 'implementation': 2, 'of': 2, 'mapreduce': 1, 'is': 2, 'usually': 2, 'not': 1, 'faster': 1, 'than': 1, 'traditional': 1, 'nonmapreduce': 1, 'any': 1, 'gains': 1, 'are': 1, 'only': 2, 'seen': 1, 'with': 1, 'multithreaded': 1, 'implementations': 1, 'on': 1, 'multiprocessor': 1, 'hardware': 1, 'the': 2, 'use': 1, 'this': 1, 'model': 1, 'beneficial': 1, 'when': 1, 'optimized': 1, 'distributed': 1, 'shuffle': 1, 'operation': 1, 'which': 1, 'reduces': 1, 'network': 1, 'communication': 1, 'cost': 1, 'and': 1, 'fault': 1}\n\n{'tolerance': 1, 'features': 1, 'of': 3, 'the': 3, 'mapreduce': 3, 'framework': 1, 'come': 1, 'into': 1, 'play': 1, 'optimizing': 1, 'communication': 1, 'cost': 1, 'is': 2, 'essential': 1, 'to': 1, 'a': 2, 'good': 1, 'algorithm': 1, 'libraries': 1, 'have': 1, 'been': 1, 'written': 1, 'in': 1, 'many': 1, 'programming': 1, 'languages': 1, 'with': 1, 'different': 1, 'levels': 1, 'optimization': 1, 'popular': 1, 'opensource': 1, 'implementation': 1, 'that': 1, 'has': 1, 'support': 1, 'for': 1, 'distributed': 1, 'shuffles': 1, 'part': 1, 'apache': 1, 'hadoop': 1}\n\n{'name': 1, 'mapreduce': 2, 'originally': 1, 'referred': 1, 'to': 2, 'the': 1, 'proprietary': 1, 'google': 2, 'technology': 1, 'but': 1, 'has': 1, 'since': 1, 'been': 1, 'genericized': 1, 'by': 1, 'was': 1, 'no': 1, 'longer': 1, 'using': 1, 'as': 1, 'their': 1, 'primary': 1, 'bigdata': 1, 'processing': 1, 'model': 1, 'and': 3, 'development': 1, 'on': 2, 'apache': 1, 'mahout': 1, 'had': 1, 'moved': 1, 'more': 1, 'capable': 1, 'less': 1, 'diskoriented': 1, 'mechanisms': 1, 'that': 1, 'incorporated': 1, 'full': 1, 'map': 1, 'reduce': 1, 'capabilities': 1}\n"
     ]
    }
   ],
   "source": [
    "batchsize = 50\n",
    "text_words = text.split()\n",
    "text_chunks = []\n",
    "while text_words:\n",
    "    text_chunks.append(text_words[:batchsize])\n",
    "    text_words = text_words[batchsize:]\n",
    "\n",
    "partial_results = list(map(count_words, text_chunks))\n",
    "print(*partial_results, sep='\\n\\n')"
   ]
  },
  {
   "source": [
    "Now we have seven groups of partial results which we need to combine in order to have get the total counting of each word."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'mapreduce': 11, 'is': 9, 'a': 13, 'programming': 3, 'model': 4, 'and': 15, 'an': 1, 'associated': 1, 'implementation': 4, 'for': 7, 'processing': 3, 'generating': 1, 'bigdata': 2, 'sets': 1, 'with': 3, 'parallel': 2, 'distributed': 4, 'algorithm': 2, 'on': 4, 'cluster': 1, 'program': 1, 'composed': 1, 'of': 11, 'map': 4, 'procedure': 1, 'which': 4, 'performs': 2, 'filtering': 1, 'sorting': 2, 'such': 3, 'as': 5, 'students': 2, 'by': 5, 'first': 1, 'name': 4, 'into': 2, 'queues': 1, 'one': 1, 'queue': 2, 'each': 2, 'reduce': 5, 'method': 1, 'summary': 1, 'operation': 2, 'counting': 1, 'the': 24, 'number': 1, 'in': 6, 'yielding': 1, 'frequencies': 1, 'system': 2, 'also': 1, 'called': 1, 'infrastructure': 1, 'or': 1, 'framework': 4, 'orchestrates': 1, 'marshalling': 1, 'servers': 1, 'running': 1, 'various': 2, 'tasks': 1, 'managing': 1, 'all': 1, 'communications': 1, 'data': 2, 'transfers': 1, 'between': 1, 'parts': 1, 'providing': 1, 'redundancy': 1, 'fault': 2, 'tolerance': 2, 'specialization': 1, 'splitapplycombine': 1, 'strategy': 1, 'analysis': 1, 'it': 1, 'inspired': 1, 'functions': 2, 'commonly': 1, 'used': 1, 'functional': 1, 'although': 1, 'their': 3, 'purpose': 1, 'not': 3, 'same': 1, 'original': 1, 'forms': 1, 'key': 1, 'contributions': 1, 'are': 2, 'actual': 1, 'example': 1, 'resemble': 1, 'message': 1, 'passing': 1, 'interface': 1, 'standard': 1, 'scatter': 1, 'operations': 1, 'but': 2, 'scalability': 1, 'faulttolerance': 1, 'achieved': 1, 'variety': 1, 'applications': 1, 'optimizing': 2, 'execution': 1, 'engine': 1, 'singlethreaded': 1, 'usually': 2, 'faster': 1, 'than': 1, 'traditional': 1, 'nonmapreduce': 1, 'any': 1, 'gains': 1, 'only': 2, 'seen': 1, 'multithreaded': 1, 'implementations': 1, 'multiprocessor': 1, 'hardware': 1, 'use': 1, 'this': 1, 'beneficial': 1, 'when': 1, 'optimized': 1, 'shuffle': 1, 'reduces': 1, 'network': 1, 'communication': 2, 'cost': 2, 'features': 1, 'come': 1, 'play': 1, 'essential': 1, 'to': 3, 'good': 1, 'libraries': 1, 'have': 1, 'been': 2, 'written': 1, 'many': 1, 'languages': 1, 'different': 1, 'levels': 1, 'optimization': 1, 'popular': 1, 'opensource': 1, 'that': 2, 'has': 2, 'support': 1, 'shuffles': 1, 'part': 1, 'apache': 2, 'hadoop': 1, 'originally': 1, 'referred': 1, 'proprietary': 1, 'google': 2, 'technology': 1, 'since': 1, 'genericized': 1, 'was': 1, 'no': 1, 'longer': 1, 'using': 1, 'primary': 1, 'development': 1, 'mahout': 1, 'had': 1, 'moved': 1, 'more': 1, 'capable': 1, 'less': 1, 'diskoriented': 1, 'mechanisms': 1, 'incorporated': 1, 'full': 1, 'capabilities': 1}\n"
     ]
    }
   ],
   "source": [
    "def reducer(chunks):\n",
    "    bucket = {}\n",
    "    for partial_result in chunks:\n",
    "        for word, partial_count in partial_result.items():\n",
    "            bucket[word] = bucket.get(word, 0) + partial_count\n",
    "    return bucket\n",
    "\n",
    "print(reducer(partial_results))"
   ]
  },
  {
   "source": [
    "Now, to get the benefit of the multithreading we need to create a pool of threads passing the number of parallel tasks we want to run (in this case it will be five). Then, we spawn the tasks by mapping the function `count_words` over the chunks. Finally we combine the partial results using the function `reducer`.\n",
    "\n",
    "Notice that in order the `multiprocessing` works in a Jupyter notebook we need to save the functions and variables in a different file (here called `multithreadcore.py`) and import it in the cell."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'mapreduce': 11, 'is': 9, 'a': 13, 'programming': 3, 'model': 4, 'and': 15, 'an': 1, 'associated': 1, 'implementation': 4, 'for': 7, 'processing': 3, 'generating': 1, 'bigdata': 2, 'sets': 1, 'with': 3, 'parallel': 2, 'distributed': 4, 'algorithm': 2, 'on': 4, 'cluster': 1, 'program': 1, 'composed': 1, 'of': 11, 'map': 4, 'procedure': 1, 'which': 4, 'performs': 2, 'filtering': 1, 'sorting': 2, 'such': 3, 'as': 5, 'students': 2, 'by': 5, 'first': 1, 'name': 4, 'into': 2, 'queues': 1, 'one': 1, 'queue': 2, 'each': 2, 'reduce': 5, 'method': 1, 'summary': 1, 'operation': 2, 'counting': 1, 'the': 24, 'number': 1, 'in': 6, 'yielding': 1, 'frequencies': 1, 'system': 2, 'also': 1, 'called': 1, 'infrastructure': 1, 'or': 1, 'framework': 4, 'orchestrates': 1, 'marshalling': 1, 'servers': 1, 'running': 1, 'various': 2, 'tasks': 1, 'managing': 1, 'all': 1, 'communications': 1, 'data': 2, 'transfers': 1, 'between': 1, 'parts': 1, 'providing': 1, 'redundancy': 1, 'fault': 2, 'tolerance': 2, 'specialization': 1, 'splitapplycombine': 1, 'strategy': 1, 'analysis': 1, 'it': 1, 'inspired': 1, 'functions': 2, 'commonly': 1, 'used': 1, 'functional': 1, 'although': 1, 'their': 3, 'purpose': 1, 'not': 3, 'same': 1, 'original': 1, 'forms': 1, 'key': 1, 'contributions': 1, 'are': 2, 'actual': 1, 'example': 1, 'resemble': 1, 'message': 1, 'passing': 1, 'interface': 1, 'standard': 1, 'scatter': 1, 'operations': 1, 'but': 2, 'scalability': 1, 'faulttolerance': 1, 'achieved': 1, 'variety': 1, 'applications': 1, 'optimizing': 2, 'execution': 1, 'engine': 1, 'singlethreaded': 1, 'usually': 2, 'faster': 1, 'than': 1, 'traditional': 1, 'nonmapreduce': 1, 'any': 1, 'gains': 1, 'only': 2, 'seen': 1, 'multithreaded': 1, 'implementations': 1, 'multiprocessor': 1, 'hardware': 1, 'use': 1, 'this': 1, 'beneficial': 1, 'when': 1, 'optimized': 1, 'shuffle': 1, 'reduces': 1, 'network': 1, 'communication': 2, 'cost': 2, 'features': 1, 'come': 1, 'play': 1, 'essential': 1, 'to': 3, 'good': 1, 'libraries': 1, 'have': 1, 'been': 2, 'written': 1, 'many': 1, 'languages': 1, 'different': 1, 'levels': 1, 'optimization': 1, 'popular': 1, 'opensource': 1, 'that': 2, 'has': 2, 'support': 1, 'shuffles': 1, 'part': 1, 'apache': 2, 'hadoop': 1, 'originally': 1, 'referred': 1, 'proprietary': 1, 'google': 2, 'technology': 1, 'since': 1, 'genericized': 1, 'was': 1, 'no': 1, 'longer': 1, 'using': 1, 'primary': 1, 'development': 1, 'mahout': 1, 'had': 1, 'moved': 1, 'more': 1, 'capable': 1, 'less': 1, 'diskoriented': 1, 'mechanisms': 1, 'incorporated': 1, 'full': 1, 'capabilities': 1}\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from multithreadcore import *\n",
    "\n",
    "if __name__ == '__main__':  # only for Windows compatibility\n",
    "    with Pool(5) as pool:\n",
    "        partial_results = pool.map(count_words, text_chunks)\n",
    "        final_result = reducer(partial_results)\n",
    "        print(final_result)"
   ]
  }
 ]
}